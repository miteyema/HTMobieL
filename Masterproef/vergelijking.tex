\chapter{Vergelijking}
\label{chap:vergelijking}

Dit hoofdstuk bekijkt hoe de mobiele HTML5 raamwerken zullen worden vergeleken.
Hoofdzakelijk zal dit gebeuren aan de hand van een \term{proof of concept} (POC).
Deze wordt geïntroduceerd in sectie \ref{sec:vergelijking-poc} en zal hoofdzakelijk de gekozen vergelijkingscriteria in sectie \ref{sec:vergelijking-criteria} drijven.


\section{POC}
\label{sec:vergelijking-poc}
In sectie \ref{sec:vergelijking-poc-idee} wordt het idee van de gekozen POC besproken, waarna in sectie \ref{sec:vergelijking-poc-detail} dieper wordt ingegaan op de aspecten van de gekozen POC.

\subsection{Idee}
\label{sec:vergelijking-poc-idee}

In samenspraak met Capgemini werd gekozen om een POC op te stellen.
Dit is een idee waarbij de uitvoerbaarheid in de verschillende raamwerken kan worden nagegaan.
Verschillende vergaderingen werden georganiseerd om tot een idee te komen dat vooral in de bedrijfswereld van toepassing is.
Het uiteindelijke idee is een applicatie die het mogelijk maakt voor werknemers om hun onkosten via hun mobiel apparaat door te sturen.

Het idee werd uitgewerkt door Capgemini en geleverd aan de auteurs als \term{mockup}.
Dit is een voorstelling van de applicatie als een reeks schermen zoals deze er zouden uitzien op een apparaat. 
Een voorbeeld van zo een scherm is te vinden op figuur~\ref{fig:poc}. 
De bedoeling is dat deze POC wordt uitgewerkt zowel voor smartphone als tablet, zowel voor Android als iOS, zowel voor staande als liggende apparaten en zowel voor online als offline gebruik.

\begin{figure}
  \centering
  \includegraphics[trim=0cm 4cm 0cm 1.25cm,clip=true,height=7.5cm]{figuren/poc.pdf}
  \caption{POC bij het toevoegen van een nieuwe onkost met aan de linkerkant de weergave op een tablet en aan de rechterkant deze op een smartphone.}
  \label{fig:poc}
\end{figure}

\subsection{Aspecten}
\label{sec:vergelijking-poc-detail}

Een werknemer meldt zich eerst aan op de applicatie en kan daarna ofwel een nieuw onkostenformulier aanmaken of zijn doorgestuurde onkostenformulieren bekijken.
De term onkostenformulier is een groepering van meerdere onkosten met bijhorende bewijsstukken en de handtekening van de werknemer. 
Het aanmaken van een nieuw onkostenformulier verloopt in vier stappen.
Indien de werknemer al eerder begonnen was met het aanmaken van een formulier, zal hij worden gevraagd of hij verder wil gaan met dat formulier of met een nieuw formulier wil starten.

\begin{enumerate}
\item De eerste stap is het bekijken en/of aanpassen van zijn persoonlijke informatie.
Bij het aanpassen van deze gegevens, zullen deze worden gevalideerd.
Indien deze validatie faalt, krijg de werknemer een dialoogvenster te zien met de reden tot falen.
Ook worden de foute velden rood gemarkeerd.

\item In de tweede stap kan hij zijn toegevoegde onkosten aan het formulier bekijken.
In het begin is deze lijst leeg, tenzij hij eerder een formulier aan het invullen was (zie infra).
Indien deze lijst onkosten bevat, is het mogelijk om hierop te klikken en deze te bekijken. Aanpassen is niet mogelijk.

\item In stap drie kan een nieuwe onkost worden toegevoegd.
Dit kan ofwel een binnenlandse of buitenlandse onkost zijn.
Voor beide dient een datum en projectcode te worden opgegeven.
De eerstgenoemde is een \term{datepicker} die teruggaat tot twee maanden in de tijd.
De laatstgenoemde bevat automatische aanvulling, maar de werknemer is niet verplicht om een projectcode uit de aanvulling te selecteren.
Daarnaast dient het type en bedrag van de onkost, alsook een bewijsstuk te worden opgegeven.
Bij een buitenlands onkost moet de munteenheid worden opgegeven, waarna de applicatie deze automatisch omvormt naar euro.
Het scherm voor het toevoegen van een buitenlandse onkost wordt getoond op figuur \ref{fig:poc}. 
Net zoals bij stap één geldt ook hier validatie op de formuliervelden.

\item In deze laatste stap dient een handtekening te worden geplaatst waarna het formulier kan worden doorgestuurd.
Indien de gebruiker offline werkt, zal deze worden opgeslagen op het toestel.
De werknemer kan als hij terug online is, het formulier opnieuw doorsturen.
Indien de werknemer online is, maar toch nog wil wachten om het formulier door te sturen, kan hij de applicatie afsluiten en later verder gaan met het formulier.

\end{enumerate}

Bij het bekijken van de doorgestuurde formulieren is het mogelijk om per formulier de bijhorende PDF te downloaden. 
Deze bevat een overzicht van de onkosten met bijhorende bewijsstukken, alsook de handtekening van de werknemer.

\section{Vergelijkingscriteria}
\label{sec:vergelijking-criteria}

% TODO zeggen WAAROM we deze criteria hebben gekozen en niet de andere, WAAROM de onze 'beter' zijn, WAAROM we reeds bestaande hebben genomen tezamen met nieuwe, …

In deze sectie zullen we de criteria toelichten die we zullen toepassen om de raamwerken te vergelijken.
In sectie \ref{sec:vergelijken-raamwerken} werden reeds technieken besproken die in de literatuur worden toegepast.
Elementen van deze technieken zullen terugkomen in onze methode om de raamwerken te evalueren.

Vijf grote criteria zullen gebruikt worden:  gemeenschap (\ref{sec:vergelijking-gemeenschap}), productiviteit (\ref{sec:vergelijking-productiviteit}), gebruik (\ref{sec:vergelijking-gebruik}), ondersteuning (\ref{sec:vergelijking-ondersteuning}) en performantie (\ref{sec:vergelijking-performantie}). 
Elk raamwerk krijgt voor elk criterium een score. 
Deze scores zullen in een \term{spiderweb} worden ondergebracht.  
Dit is een grafiek met vijf dimensies,  de criteria,     waar elke score in de overeenkomstige as met relatieve schaal wordt geplot.
Zoals hierboven vermeld zal een POC gebruikt worden bij de vergelijking.
De implementatie van deze POC zal het productiviteits-, gebruiks- en ondersteuningscriterium drijven.  
Dit komt omdat de auteurs ervan uitgaan dat de POC voldoende verschillende functionaliteit bevat om een goeie vergelijking te kunnen maken.
De score van performantie zal deels bepaald worden door de laadtijden van de POC.

%Niet bekeken criteria:
% Het bedrijf dat het raamwerk aanbiedt
% De marktadoptatie van het raamwerk (belangrijkste klanten)
% De licenties en kosten die samen gaan bij het gebruik van het raamwerk
% Betalende probleemoplossingen (professionele ondersteuning)
% De laatste nieuwe versie van het raamwerk
% De documentatie, handleidingen en voorbeelden die voorhanden zijn
% Bibliotheken waar het raamwerk op steunt
% De tools die de programmeur kan gebruiken om sneller te ontwikkelen

\subsection{Gemeenschap}
\label{sec:vergelijking-gemeenschap}
% 'makkelijk'
De gemeenschap en populariteit van een raamwerk is makkelijk in cijfers uit te drukken. 
We voorzien een tabel waar we per raamwerk het aantal volgers op Twitter, watchers/forkers van GitHub en aantal likes van Facebook zullen onderbrengen~\cite{Sarrafi2012a,Ayuso2012}. 
%github nul geven als het niet beschikbaar is => verantwoorden dat het open source is
Een grafiek van Google Trends, die het zoekvolume op Google uitzet per tijd, zal voor elk raamwerk na deze tabel worden toegevoegd.
%TODO zoals bij onze presentatie gezegd:  ook cijfers per tijd bekijken OK
%TODO nederlandse letters gebruiken, dus T_v voor Twitter volgers, r ipv f voor raamwerk, ...

De som van Twitter volgers ($T_f$), GitHub sterren ($G_s$), GitHub forkers ($G_f$), Stack Overflow vragen ($G_{so}$) en Facebook likes ($F_f$) vormt de score voor het gemeenschapscriteria:
\begin{equation} %TODO aanpassen
  G_f={T_f+G_s+G_f+G_{so}+F_f}
  \label{eq:gemeenschap}
\end{equation}
met $f$ de verschillende raamwerken.

\subsection{Productiviteit}
\label{sec:vergelijking-productiviteit}
De productiviteit moet een indicatie geven hoe lang het duurt om met het raamwerk vertrouwd te raken. 
%TODO assumptie:  beide gemeensch achtergrond
%TODO de auteurs
Twee personen met een gemeenschappelijke achtergrond zullen het raamwerk testen met een implementatie.
Elk zullen ze de POC en een extra loginscherm maken in vier verschillende raamwerken maken.
Persoon $1$ maakt de POC in raamwerk $A$ en $B$ en het loginscherm in $C$ en $D$.
Persoon $2$ zal dan de POC in raamwerk $C$ en $D$ maken en de loginschermen in $A$ en $B$.
De tijd die nodig is om de volledige POC te implementeren is een indicatie voor de productiviteit. 
De implementatie van het loginscherm is een extra test.
Dit scherm bevat UI-elementen, validaties en \term{backend} integratie en kan dit dus als voldoende steekproef beschouwd worden om ervaring met een raamwerk te testen.
Het zal een indicatie geven hoe snel,  zonder al te veel voorkennis van het raamwerk,  één specifiek scherm kan opgeleverd worden.
%Ook zullen beide een loginscherm maken in de andere twee raamwerken~\cite{Burris}. 
%We  
De tijd die ieder nodig heeft om dit scherm te bouwen, geeft ook een indicatie van de nodige leertijd.
%TODO r ipv f voor raamwerken
De som van de uren voor het implementeren van de POC ($t_{f,POC}$) en het loginscherm ($t_{f,login}$) vormt de score voor de productiviteit:
\begin{equation}
  Pr_f = {t_{f,POC} + t_{f,login}}
  \label{eq:productiviteit}
\end{equation}
waar $f$ de verschillende raamwerken voorstellen.

\subsection{Gebruik}
\label{sec:vergelijking-gebruik}
% Om het verschil in gebruik van de raamwerken te onderzoeken, zullen we steunen op de logboeken die we hebben bijgehouden tijdens het implementeren van de POC. 

% TODO: ik zou onderstaande zin uit gebruik trekken, is ook relevant voor productiviteit en ondersteuning
Men kan ervan uitgaat dat de POC alle relevante kenmerken bevat om de raamwerken zoveel mogelijk uit te buiten. 
Deze POC kan onderverdeeld worden in verschillende deelproblemen.
Deze deelproblemen worden als uitdaging aan het raamwerk voorgelegd.
De wijze waarop het raamwerk de uitdaging aangaat zal tot een score voor de uitdaging leiden.
In totaal onderscheiden we drie gevallen.
De hoogste score wordt toegekend wanneer bepaalde functionaliteit reeds aangeboden wordt door het raamwerk. 
Een lagere score betekent dat een plug-in werd gezocht. 
Wanneer de code voor het overgrote deel zelf diende geschreven te worden of een hack noodzakelijk was, zal de laagste score worden toegekend.
Tabel \ref{tabel:scores-uitdagingen} toont de mogelijke scores $S_{f,i}$ van raamwerk $f$ en voor uitdaging $i$.
\begin{table}[h]	
  \centering
  \begin{tabular}{ll}
    \toprule
    \textbf{Score} & \textbf{Beoordelingscriteria}\\
    \midrule
    $S_{f,i} = 2$ & Ondersteund door het raamwerk\\
    $S_{f,i} = 1$ & Een plug-in is nodig\\
    $S_{f,i} = 0$ & Eigen implementatie of hack\\
    \bottomrule
  \end{tabular}
  \caption{Beoordeling uitdagingen gebruikscriterium}
  \label{tabel:scores-uitdagingen}
\end{table}
\begin{equation}
  G_f = \sum_{i=1}^{13}{\left(S_{f,i}\right)}
  \label{eq:gebruik}
\end{equation}
met $f$ de verschillende raamwerken en $i$ het aantal uitdagingen.

%TODO tabel met alle uitdagingen?

\subsection{Ondersteuning}
\label{sec:vergelijking-ondersteuning}
Dit criterium moet weergeven hoe goed het raamwerk verschillende toestellen met hun verschillende besturingssystemen ondersteund.
% TODO: duidelijker uitleggen hoe dat zit met browser en OS, nu veel te kort tussen haakjes aangehaald
Enkel de standaard browser van het BS (Android browser/Chrome en Safari) zal beschouwd worden.
We spreken van een \term{context} als we één bepaalde configuratie van toestel, BS en browser bedoelen.
Alle uitdagingen die gebruikt zijn om het gebruikscriterium te testen, komen ook hier van pas.
In elke context zullen de $13$ uitdagingen testen die we in vorige sectie hebben opgesteld.
De correcte weergave en uitvoering van elke uitdaging binnen een context bepalen de score voor die context.
Deze score kan enkel $0$ of $1$ zijn respectievelijk een probleem of correcte uitvoering.
Per context brengen we ook de marktwaarde van het toestel in rekening om de meest gebruikte toestellen te bevoordelen.
In tabel \ref{tabel:toestellen-hci} staan de verschillende contexten met hun marktwaarde weergegeven.

De gewogen som van de scores van de verschillende contexten bepaalt de score van het ondersteuningscriterium:
\begin{equation}
  O_f = \sum_{d=1}^{8}{\left(\sum_{i=1}^{13}S_{f,i}*W_d\right)}
  \label{eq:ondersteuning}
\end{equation}
met $f$ de verschillende raamwerken,  $d$ de verschillende toestellen en $i$ de uitdagingen. 
% We zullen een scenario uitwerken waarbij we het gebruik van de POC doorlopen. 
% Dit scenario zullen we op een reeks van verschillende mobiele apparaten herhalen~\cite{Sarrafi2012a}. 
% Bij het mislukken van een stap in het scenario, zal een punt worden afgetrokken. 
% Hierdoor kunnen we een score bekomen hoe goed de applicatie, geïmplementeerd in een bepaald raamwerk, scoort op een bepaald apparaat. 
%De gebruikte apparaten araten aan het departement HCI.
Een kanttekening bij dit criterium is of het raamwerk ondersteunt de webapplicatie om te vormen tot een \term{native} applicatie. 
% TODO nog eens uitleggen war we met native look-and-feel bedoelen
Ook bekijken we of de \term{native look-and-feel} per besturingssysteem door het raamwerk kan worden benaderd.

\begin{table}[h]
  \centering
  \begin{tabular}{lllll}
    \toprule
    \textbf{Toestel} & \textbf{Soort} &\textbf{Besturingssysteem} & \textbf{Browser} & \textbf{Marktwaarde}\\
    \midrule
    HTCDesireZ & & Android 2.3.3 &  & \\
    GalaxyTab & & Android 2.3.6 &  & \\
    Galaxy Gio & & Android 2.3.6 &  & \\
    Galaxy Ace 2 & & Android 2.3.6 &  & \\
    GalaxySII & & Android 4.1.2 &  & \\
    Nexus 7 & &Android 4.2.1  &  & \\
    iPad3 4GWiFi & & iOS 6.0.1 &  & \\
    iPhone 3GS & & iOS 6.0.1 &  & \\
    \bottomrule
  \end{tabular}
  \caption{Beschikbare toestellen met hun besturingssysteem, browser en gewicht}
  \label{tabel:toestellen-hci}
\end{table}

\subsection{Performantie}
\label{sec:vergelijking-performantie}
Dit criterium zal de laattijden van het raamwerk in rekening brengen.
De tijd die nodig is om één of meerder pagina's te laden zal bepaald worden met Google Page Speed~\cite{Morgan2011}. 
Hiervoor zullen verschillende testen worden uitgevoerd. 
Ten eerste zal de laadtijd van de volledig geïmplementeerde POC bekeken worden ($r_{f,POC}$). 
Daarnaast zullen geïsoleerde testen met het verzenden van een AJAX request uitgevoerd worden ($r_{f,AJAX}$).
Daar wordt het effect van het versturen van een OPTION \term{request} bekeken wanneer een verzoek naar een ander domeinen wordt gestuurd.
%TODO exacte info tests + extra info CORS zoeken

%Verdergaand op het versturen van requests zullen we kijken hoe lang het duurt vooraleer een expense daadwerkelijk verzonden is naar de backend.
Verder zijn er ook geïsoleerde testen met UI-elementen. 
Hier zal een \term{dummy} pagina voorzien worden 1000 knoppen van het raamwerk en bepaalt Google Page Speed de laadtijd ($r_{f,UI}$). 
%TODO exacte UI tests hier uitleggen
Als laatste zullen de loginschermen die in sectie \ref{sec:vergelijking-productiviteit} werden geïntroduceerd, worden gebruikt ($t_{r,login}$). 
De redenen waarom deze geïsoleerde applicatie wordt gebruiken is omdat men ervan uit kan gaan dat niet de volledige POC in ieder raamwerk zal kunnen worden geïmplementeerd. 
Dit is in tegenstelling tot dit scherm, waarbij we exact het aantal lijnen cod een bijhorende performantie kunnen vergelijken.

De formule voor het performantiecriterium wordt dan: 

\begin{equation}
  Pe_f=r_{f,POC}+r_{f,AJAX}+r_{f,UI}+r_{f,login} 
  \label{eq:performantie}
\end{equation}
met $f$ de verschillende raamwerken.
